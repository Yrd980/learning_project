import requests
import json
import csv
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from tqdm import tqdm  # éœ€è¦å®‰è£…ï¼špip install tqdm

# é…ç½®å‚æ•°
TOKEN = ""  # æ›¿æ¢ä¸ºä½ çš„ GitHub Token
HEADERS = {"Authorization": f"token {TOKEN}"}
PER_PAGE = 100      # æ¯é¡µæ•°é‡ (GitHub æœ€å¤§å…è®¸ 100)
TIMEOUT = 10        # è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
MAX_RETRIES = 3     # æœ€å¤§é‡è¯•æ¬¡æ•°

def setup_session():
    """é…ç½®å¸¦é‡è¯•æœºåˆ¶çš„ Session"""
    session = requests.Session()
    retry_strategy = Retry(
        total=MAX_RETRIES,
        backoff_factor=1,
        status_forcelist=[500, 502, 503, 504]
    )
    adapter = HTTPAdapter(max_retries=retry_strategy)
    session.mount("https://", adapter)
    session.mount("http://", adapter)
    return session

def fetch_all_starred(session):
    """è·å–æ‰€æœ‰æ˜Ÿæ ‡ä»“åº“æ•°æ®"""
    page = 1
    repos = []
    with tqdm(desc="ğŸ“¥ Fetching pages", unit="page", leave=False) as pbar:
        while True:
            url = f"https://api.github.com/users/username/starred?per_page={PER_PAGE}&page={page}"
            try:
                response = session.get(url, headers=HEADERS, timeout=TIMEOUT)
                response.raise_for_status()
                data = response.json()
                
                if not data:
                    break
                
                repos.extend(data)
                pbar.set_postfix({"repos": len(repos)})
                pbar.update(1)
                page += 1

            except Exception as e:
                print(f"\nâš ï¸ Error on page {page}: {str(e)}")
                break
    return repos

def save_data(repos):
    """ä¿å­˜æ•°æ®åˆ° JSON å’Œ CSV"""
    # ä¿å­˜ä¸º JSON
    with open("starred_repos.json", "w") as f:
        json.dump(repos, f, indent=2)

    # ä¿å­˜ä¸º CSV
    with open("starred_repos.csv", "w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow([
            "Name", "URL", "Description", 
            "Language", "Stars", "Archived"
        ])
        
        for repo in tqdm(repos, desc="ğŸ’¾ Saving CSV", unit="repo"):
            writer.writerow([
                repo["full_name"],
                repo["html_url"],
                repo["description"] or "",  # å¤„ç† null å€¼
                repo["language"] or "N/A",
                repo["stargazers_count"],
                repo["archived"]
            ])

if __name__ == "__main__":
    print("ğŸš€ Starting GitHub Starred Repos Export")
    
    # åˆå§‹åŒ– Session
    session = setup_session()
    
    # è·å–æ‰€æœ‰ä»“åº“æ•°æ®
    print("â³ Downloading repository data...")
    repositories = fetch_all_starred(session)
    
    # ä¿å­˜æ•°æ®
    print(f"\nâœ… Downloaded {len(repositories)} repositories")
    save_data(repositories)
    
    # ç»“æœè¾“å‡º
    print("\nğŸ‰ Export completed!")
    print(f"ğŸ“‚ JSON file: starred_repos.json")
    print(f"ğŸ“Š CSV file: starred_repos.csv")
