import gradio as gr
import torch
import pandas as pd
from model import SentimentModel, ModelConfig
from transformers import BertTokenizer
import logging
import os


class SentimentAnalyzer:
    def __init__(self, model_path):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")
        config = ModelConfig()
        config.vocab_size = self.tokenizer.vocab_size
        self.model = SentimentModel(config).to(self.device)
        checkpoint = torch.load(model_path, map_location=self.device)
        self.model.load_state_dict(checkpoint["model_state_dict"])
        self.model.eval()

    def predict_text(self, text, max_length=128):
        if not text.strip():
            return "please input content"

        encoding = self.tokenizer(
            text,
            add_special_tokens=True,
            max_length=max_length,
            padding="max_length",
            truncation=True,
            return_tensors="pt",
        )

        input_ids = encoding["input_ids"].to(self.device)
        attention_mask = encoding["attention_mask"].to(self.device)

        with torch.no_grad():
            outputs = self.model(input_ids, attention_mask)
            probabilities = torch.nn.functional.softmax(outputs, dim=1)

        probs = probabilities[0].cpu().numpy()
        sentiment_map = {0: "negative", 1: "normal", 2: "positive"}
        prediction = sentiment_map[probs.argmax()]

        result = f"âœ¨ sentiment analysis resultï¼š{prediction}\n\n"
        result += "ğŸ“Š probabilities distributionï¼š\n"
        result += f"negative: {probs[0]:.2%}\n"
        result += f"normal: {probs[1]:.2%}\n"
        result += f"positive: {probs[2]:.2%}"  # æ·»åŠ æƒ…æ„Ÿæ ‡ç­¾çš„é¢œè‰²æç¤º
        color_map = {"negative": "ğŸ”´", "normal": "âšª", "positive": "ğŸŸ¢"}
        result = f"{color_map[prediction]} {result}"

        return result

    def predict_file(self, file):
        if file is None:
            return "please upload csv file"

        try:
            df = pd.read_csv(file.name)
            if "review" not in df.columns:
                return "error: csv file must contain 'review' column"

            results = []
            for text in df["review"]:
                encoding = self.tokenizer(
                    str(text),
                    add_special_tokens=True,
                    max_length=128,
                    padding="max_length",
                    truncation=True,
                    return_tensors="pt",
                )
                input_ids = encoding["input_ids"].to(self.device)
                attention_mask = encoding["attention_mask"].to(self.device)

                with torch.no_grad():
                    outputs = self.model(input_ids, attention_mask)
                    _, predicted = torch.max(outputs, 1)
                    results.append(predicted.item())

            # æ·»åŠ é¢„æµ‹ç»“æœåˆ°DataFrame
            sentiment_map = {0: "negative", 1: "normal", 2: "positive"}
            df["predict_sentiment"] = [sentiment_map[pred] for pred in results]

            # ä¿å­˜ç»“æœ
            output_path = "result.csv"
            df.to_csv(output_path, index=False)
            return (
                f"âœ… predict finishï¼result save to {output_path}\n\nğŸ“Š sentiment distribution ï¼š\n"
                + f"positiveï¼š{(df['predict_sentiment']=='positive').sum()} æ¡\n"
                + f"normalï¼š{(df['predict_sentiment']=='normal').sum()} \n"
                + f"negativeï¼š{(df['predict_sentiment']=='negative').sum()} "
            )
        except Exception as e:
            return f"âŒ fail to process fileï¼š{str(e)}"



